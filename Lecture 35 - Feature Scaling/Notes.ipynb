{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db9d7dfb",
   "metadata": {},
   "source": [
    "# What is Feature Scaling?\n",
    "- Feature Scaling means adjusting the values of different features (columns) so that they are on a similar scale — typically in the range [0, 1] or [-1, 1].\n",
    "\n",
    "- In simple terms: It ensures that all features (inputs) contribute fairly to the model, rather than one feature dominating others just because of its scale.\n",
    "\n",
    "Example (Before Scaling)\n",
    "| Feature | Description   | Typical Range |\n",
    "| ------- | ------------- | ------------- |\n",
    "| Age     | Person’s age  | 0 – 100       |\n",
    "| Income  | Yearly income | 0 – 100,000   |\n",
    "\n",
    "\n",
    "If you feed both features directly into a model:\n",
    "\n",
    "- The model might give more importance to “Income” just because its numbers are larger (100,000 vs 100).\n",
    "- Even if “Age” is equally important!\n",
    "So — we scale features to balance them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02562429",
   "metadata": {},
   "source": [
    "### Why We Use Feature Scaling?\n",
    "| Reason                               | Explanation                                                                                                                                                                              |\n",
    "| ------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **1️⃣ Gradient Descent Convergence** | Models like Linear Regression, Logistic Regression, Neural Networks use Gradient Descent — if features have very different scales, the algorithm converges **slowly** or **gets stuck**. |\n",
    "| **2️⃣ Fair Feature Contribution**    | Ensures all features affect the model equally (no bias toward large numbers).                                                                                                            |\n",
    "| **3️⃣ Distance-Based Models**        | For KNN, SVM, K-Means — distances are sensitive to scale. Scaling prevents “large range” features from dominating.                                                                       |\n",
    "| **4️⃣ Improves Performance**         | Scaling can speed up training and improve accuracy.                                                                                                                                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79297d2e",
   "metadata": {},
   "source": [
    "### How We Do Feature Scaling\n",
    "There are two main techniques:\n",
    "1. Normalization (Min Max Scaling)\n",
    "2. Standardization (Z-score Scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54cac06",
   "metadata": {},
   "source": [
    "### 1. Normalization (Min-Max Scaling)\n",
    "Scales values to a fixed range [0, 1].\n",
    "\n",
    "$$\n",
    "X_{\\text{scaled}} = \\frac{X - X_{\\min}}{X_{\\max} - X_{\\min}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f849327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  ]\n",
      " [0.25]\n",
      " [0.5 ]\n",
      " [0.75]\n",
      " [1.  ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "data = np.array([[10], [20], [30], [40], [50]])\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad63777b",
   "metadata": {},
   "source": [
    "Best when:\n",
    "- You need bounded data (e.g., neural networks with sigmoid activation).\n",
    "- You want to preserve relative relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d615b66a",
   "metadata": {},
   "source": [
    "### 2. Standardization (Z-score Scaling)\n",
    "- Centers data around mean = 0 and standard deviation = 1.\n",
    "\n",
    "$$\n",
    "X_{\\text{scaled}} = \\frac{X - \\mu}{\\sigma}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e70eff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.41421356]\n",
      " [-0.70710678]\n",
      " [ 0.        ]\n",
      " [ 0.70710678]\n",
      " [ 1.41421356]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "data = np.array([[10], [20], [30], [40], [50]])\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "print(scaled_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4899d2e6",
   "metadata": {},
   "source": [
    "Best when:\n",
    "- You use models assuming normal distribution (e.g., Linear Regression, Logistic Regression, PCA, SVM).\n",
    "- Features have outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a28f54",
   "metadata": {},
   "source": [
    "### Where We Use Feature Scaling\n",
    "| Algorithm Type                     | Scaling Required? | Reason                              |\n",
    "| ---------------------------------- | ----------------- | ----------------------------------- |\n",
    "| **Linear Regression**              | ✅ Yes             | Gradient descent converges faster   |\n",
    "| **Logistic Regression**            | ✅ Yes             | Improves convergence                |\n",
    "| **SVM (Support Vector Machines)**  | ✅ Yes             | Distance-based algorithm            |\n",
    "| **KNN (K-Nearest Neighbors)**      | ✅ Yes             | Uses Euclidean distance             |\n",
    "| **K-Means Clustering**             | ✅ Yes             | Uses distance metric                |\n",
    "| **Neural Networks**                | ✅ Yes             | Improves gradient flow              |\n",
    "| **Decision Trees / Random Forest** | ❌ No              | Tree splits are not scale-sensitive |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ddc451",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aa5464e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Scaling:\n",
      "    Age  Income\n",
      "0   18   20000\n",
      "1   25   35000\n",
      "2   32   60000\n",
      "3   47  120000\n",
      "4   54  200000\n",
      "\n",
      "After Scaling:\n",
      "         Age    Income\n",
      "0 -1.280023 -1.015152\n",
      "1 -0.759083 -0.787879\n",
      "2 -0.238144 -0.409091\n",
      "3  0.878155  0.500000\n",
      "4  1.399095  1.712121\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Sample dataset\n",
    "data = pd.DataFrame({\n",
    "    'Age': [18, 25, 32, 47, 54],\n",
    "    'Income': [20000, 35000, 60000, 120000, 200000]\n",
    "})\n",
    "\n",
    "print(\"Before Scaling:\\n\", data)\n",
    "\n",
    "# Apply StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=['Age', 'Income'])\n",
    "print(\"\\nAfter Scaling:\\n\", scaled_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614f736e",
   "metadata": {},
   "source": [
    "### Summary\n",
    "| Concept   | Meaning                                              |\n",
    "| --------- | ---------------------------------------------------- |\n",
    "| **What**  | Rescaling features so they have similar ranges       |\n",
    "| **Why**   | To ensure fair contribution and faster learning      |\n",
    "| **How**   | Min-Max (Normalization) or Z-score (Standardization) |\n",
    "| **Where** | Gradient-based and distance-based ML models          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cf5fca",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "svastikkka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
